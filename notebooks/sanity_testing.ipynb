{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8339938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.gpt import GPT, GPTConfig\n",
    "from src.data.loader import build_loaders\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = build_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61abc460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae2b0e2d141473495b577f4cf4fb9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Check:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10, Loss: 6.067510604858398\n",
      "Step 20, Loss: 5.553730010986328\n",
      "Step 30, Loss: 5.319214820861816\n",
      "Step 40, Loss: 5.273548603057861\n",
      "Step 50, Loss: 5.238977432250977\n",
      "Step 60, Loss: 5.206088066101074\n",
      "Step 70, Loss: 5.091506481170654\n",
      "Step 80, Loss: 4.8884100914001465\n",
      "Step 90, Loss: 4.705275535583496\n",
      "Step 100, Loss: 4.512551307678223\n",
      "Step 110, Loss: 4.352654457092285\n",
      "Step 120, Loss: 4.133951663970947\n",
      "Step 130, Loss: 3.948316812515259\n",
      "Step 140, Loss: 3.7919375896453857\n",
      "Step 150, Loss: 3.513129234313965\n",
      "Step 160, Loss: 3.295459270477295\n",
      "Step 170, Loss: 3.115892171859741\n",
      "Step 180, Loss: 2.854937791824341\n",
      "Step 190, Loss: 2.649583578109741\n",
      "Step 200, Loss: 2.4090089797973633\n",
      "Step 210, Loss: 2.2263031005859375\n",
      "Step 220, Loss: 1.985011100769043\n",
      "Step 230, Loss: 1.7931561470031738\n",
      "Step 240, Loss: 1.5859116315841675\n",
      "Step 250, Loss: 1.4720110893249512\n",
      "Step 260, Loss: 1.2628357410430908\n",
      "Step 270, Loss: 1.0978960990905762\n",
      "Step 280, Loss: 0.9371634125709534\n",
      "Step 290, Loss: 0.7801907658576965\n",
      "Step 300, Loss: 0.6650741100311279\n",
      "Step 310, Loss: 0.569259524345398\n",
      "Step 320, Loss: 0.47394052147865295\n",
      "Step 330, Loss: 0.3836948871612549\n",
      "Step 340, Loss: 0.3374510109424591\n",
      "Step 350, Loss: 0.2777562439441681\n",
      "Step 360, Loss: 0.24063876271247864\n",
      "Step 370, Loss: 0.21017403900623322\n",
      "Step 380, Loss: 0.18467473983764648\n",
      "Step 390, Loss: 0.1517251431941986\n",
      "Step 400, Loss: 0.13904671370983124\n",
      "Step 410, Loss: 0.12879358232021332\n",
      "Step 420, Loss: 0.11049091070890427\n",
      "Step 430, Loss: 0.08277536183595657\n",
      "Step 440, Loss: 0.084110789000988\n",
      "Step 450, Loss: 0.07577918469905853\n",
      "Step 460, Loss: 0.06793566048145294\n",
      "Step 470, Loss: 0.06631939858198166\n",
      "Step 480, Loss: 0.0613800548017025\n",
      "Step 490, Loss: 0.055895086377859116\n",
      "Step 500, Loss: 0.048219434916973114\n"
     ]
    }
   ],
   "source": [
    "# Overfit on a single batch\n",
    "sanity_model = GPT(GPTConfig(vocab_size=10000))\n",
    "sanity_optimizer = torch.optim.Adam(sanity_model.parameters(), lr=3e-3)\n",
    "batch = next(iter(train_loader))\n",
    "inputs, targets = batch['input_ids'], batch['labels']\n",
    "for step in tqdm(range(1, 501), desc='Sanity Check'):\n",
    "    outputs = sanity_model(inputs, targets)\n",
    "    logits, loss = outputs['logits'], outputs['loss']\n",
    "    sanity_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    sanity_optimizer.step()\n",
    "    if step % 10 == 0:\n",
    "        print(f'Step {step}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6973cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_acc: 0.9869384765625\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    logits = sanity_model(input_ids=inputs, labels=targets)['logits']\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    mask = targets.ne(-100)\n",
    "    acc = (predictions[mask] == targets[mask]).float().mean().item()\n",
    "    print(\"token_acc:\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
